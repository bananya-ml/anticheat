{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "This notebook will cover the iterative process of training multiple models to find one best suited to our needs, and then further explore the possibilities of improving the selected model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.time_series import DevNetTS, PReNetTS, DeepSADTS, DeepSVDDTS, DeepIsolationForestTS, AnomalyTransformer, COUTA, TcnED, TimesNet, TranAD, USAD\n",
    "from deepod.models.tabular import DeepSAD, DeepSVDD, DeepIsolationForest, RCA, REPEN, RDP, RoSAS, GOAD, NeuTraL, ICL, SLAD, DevNet, PReNet, FeaWAD\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepod.metrics import ts_metrics\n",
    "from deepod.metrics import point_adjustment\n",
    "from deepod.metrics import tabular_metrics\n",
    "import joblib\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the variable 'data_dir' with the location of the combined data file to be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir= \"../../data/anomalyDataset.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2280812, 40)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2280812 entries, 0 to 2280811\n",
      "Data columns (total 40 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   tick               float64\n",
      " 1   seconds            float64\n",
      " 2   clockTime          float64\n",
      " 3   attackerSteamID    float64\n",
      " 4   zoomLevel          float64\n",
      " 5   ctAlivePlayers     float64\n",
      " 6   entityId           float64\n",
      " 7   penetratedObjects  float64\n",
      " 8   steamID            float64\n",
      " 9   ping               float64\n",
      " 10  endTick            float64\n",
      " 11  tScore             float64\n",
      " 12  ctScore            float64\n",
      " 13  victimName         int64  \n",
      " 14  weapon             int64  \n",
      " 15  weaponClass        int64  \n",
      " 16  hitGroup           int64  \n",
      " 17  mapName            int64  \n",
      " 18  lastPlaceName      int64  \n",
      " 19  ctTeam             int64  \n",
      " 20  winningSide        int64  \n",
      " 21  roundEndReason     int64  \n",
      " 22  playerName         int64  \n",
      " 23  attackerStrafe     int64  \n",
      " 24  isSuicide          int64  \n",
      " 25  isHeadshot         int64  \n",
      " 26  isAlive            int64  \n",
      " 27  isBot              int64  \n",
      " 28  isAirborne         int64  \n",
      " 29  isStanding         int64  \n",
      " 30  playerStrafe       int64  \n",
      " 31  player             float64\n",
      " 32  playerView         float64\n",
      " 33  attacker           float64\n",
      " 34  velocity           float64\n",
      " 35  attackerView       float64\n",
      " 36  eye                float64\n",
      " 37  view               float64\n",
      " 38  pos                float64\n",
      " 39  label              int64  \n",
      "dtypes: float64(21), int64(19)\n",
      "memory usage: 696.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will select a subset of the total data to quickly iterate over all available models and test their performances without changing the default hyperparameters, to set a baseline for improving performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df.iloc[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Remember, our data has a temporal dependence, i.e., there is an order of events that makes sense. Hence, we cannot shuffle the data points and must pick a contiguous block of data as our subset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sub_df.drop([\"label\"], axis=1).values\n",
    "y = sub_df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the device to GPU, if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular models\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSVDD(lr=0.0001, device=device)\n",
    "model.fit(X_train, y=None)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for DeepSVDD:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = REPEN(lr=0.0001)\n",
    "model.fit(X_train, y=None)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for REPEN:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RCA(lr=0.0001)\n",
    "model.fit(X_train, y=None)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for RCA:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RDP(lr=0.0001)\n",
    "model.fit(X_train, y=None)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for RDP:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GOAD(lr=0.0001)\n",
    "model.fit(X_train, y=None)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for GOAD:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ICL(lr=0.0001)\n",
    "model.fit(X_train, y=None)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for ICL:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuTraL(lr=0.0001)\n",
    "model.fit(X_train, y=None)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for NeuTraL:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SLAD(lr=0.0001)\n",
    "model.fit(X_train, y=None)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for SLAD:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepIsolationForest(lr=0.0001)\n",
    "model.fit(X_train, y=None)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for DeepIsolationForest:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series models\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSVDDTS(device=device, network='LSTM')\n",
    "model.fit(X_train, y=None)\n",
    "\n",
    "scores = model.decision_function(X_test)\n",
    "anomalies = X_test[scores>0.5]\n",
    "\n",
    "eval_metrics = ts_metrics(y_test, scores)\n",
    "adj_eval_metrics = ts_metrics(y_test, point_adjustment(y_test, scores))\n",
    "print(\"Results for DeepSVDDTS:\\n\",\n",
    "      f\"auc: {adj_eval_metrics[1]:.2f}, average precision: {adj_eval_metrics[1]:.2f}, f1: {adj_eval_metrics[2]:.2f}, precision: {adj_eval_metrics[3]:.2f}, recall: {adj_eval_metrics[4]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AnomalyTransformer()\n",
    "model.fit(X_train, y=None)\n",
    "\n",
    "scores = model.decision_function(X_test)\n",
    "anomalies = X_test[scores>0.5]\n",
    "\n",
    "auc, ap, f1, p, r = ts_metrics(y_test, scores)\n",
    "print(\"Results for AnomalyTransformer:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}, precision: {p:.2f}, recall: {r:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = COUTA()\n",
    "model.fit(X_train, y=None)\n",
    "\n",
    "scores = model.decision_function(X_test)\n",
    "anomalies = X_test[scores>0.5]\n",
    "\n",
    "auc, ap, f1, p, r = ts_metrics(y_test, scores)\n",
    "print(\"Results for COUTA:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}, precision: {p:.2f}, recall: {r:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TcnED()\n",
    "model.fit(X_train, y=None)\n",
    "\n",
    "scores = model.decision_function(X_test)\n",
    "anomalies = X_test[scores>0.5]\n",
    "\n",
    "auc, ap, f1, p, r = ts_metrics(y_test, scores)\n",
    "print(\"Results for TcnED:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}, precision: {p:.2f}, recall: {r:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimesNet()\n",
    "model.fit(X_train, y=None)\n",
    "\n",
    "scores = model.decision_function(X_test)\n",
    "anomalies = X_test[scores>0.5]\n",
    "\n",
    "auc, ap, f1, p, r = ts_metrics(y_test, scores)\n",
    "print(\"Results for TimesNet:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}, precision: {p:.2f}, recall: {r:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TranAD()\n",
    "model.fit(X_train, y=None)\n",
    "\n",
    "scores = model.decision_function(X_test)\n",
    "anomalies = X_test[scores>0.5]\n",
    "\n",
    "auc, ap, f1, p, r = ts_metrics(y_test, scores)\n",
    "print(\"Results for TranAD:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}, precision: {p:.2f}, recall: {r:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepIsolationForestTS()\n",
    "model.fit(X_train, y=None)\n",
    "\n",
    "scores = model.decision_function(X_test)\n",
    "anomalies = X_test[scores>0.5]\n",
    "\n",
    "auc, ap, f1, p, r = ts_metrics(y_test, scores)\n",
    "print(\"Results for DeepIsolationForestTS:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}, precision: {p:.2f}, recall: {r:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = USAD()\n",
    "model.fit(X_train, y=None)\n",
    "\n",
    "scores = model.decision_function(X_test)\n",
    "anomalies = X_test[scores>0.5]\n",
    "\n",
    "auc, ap, f1, p, r = ts_metrics(y_test, scores)\n",
    "print(\"Results for USAD:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}, precision: {p:.2f}, recall: {r:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weakly-supervised models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular models\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DevNet(lr=0.0001)\n",
    "model.fit(X_train, y=y_train)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for DevNet:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PReNet(lr=0.0001)\n",
    "model.fit(X_train, y=y_train)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for PReNet:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSAD(lr=0.001)\n",
    "model.fit(X_train, y=y_train)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for DeepSAD:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeaWAD(lr=0.0001)\n",
    "model.fit(X_train, y=y_train)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for FeaWAD:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RoSAS(lr=0.0001)\n",
    "model.fit(X_train, y=y_train)\n",
    "scores = model.decision_function(X_test)\n",
    "\n",
    "auc, ap, f1 = tabular_metrics(y_test, scores)\n",
    "print(\"Results for RoSAS:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series models\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DevNetTS(seq_len=50, )\n",
    "print(\"X:\", X_train.shape,\"y:\", y_train.shape)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "scores = model.decision_function(X_test)\n",
    "anomalies = X_test[scores>0.5]\n",
    "\n",
    "auc, ap, f1, p, r = ts_metrics(y_test, scores)\n",
    "print(\"Results for DevNetTS:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}, precision: {p:.2f}, recall: {r:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSADTS(batch_size=100, lr=0.001, rep_dim=128, hidden_dims='100,50', act='ReLU', bias=False, epoch_steps=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "scores = model.decision_function(X_test)\n",
    "anomalies = X_test[scores>0.5]\n",
    "\n",
    "auc, ap, f1, p, r = ts_metrics(y_test, scores)\n",
    "print(\"Results for DeepSADTS:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}, precision: {p:.2f}, recall: {r:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PReNetTS(batch_size=100, lr=0.001, rep_dim=128, hidden_dims='100,50', act='ReLU', bias=False, epoch_steps=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "scores = model.decision_function(X_test)\n",
    "anomalies = X_test[scores>0.5]\n",
    "\n",
    "auc, ap, f1, p, r = ts_metrics(y_test, scores)\n",
    "print(\"Results for PReNetTS:\\n\",\n",
    "      f\"auc: {auc:.2f}, average precision: {ap:.2f}, f1: {f1:.2f}, precision: {p:.2f}, recall: {r:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though our data is classified as time-series, i.e., events can only happen in a certain order, we observe that TS models tend to perform especially poorly on our dataset. This may be because a single anomaly within a 'match' unit can never be enough to predict an anomalous data point. It is a series of multiple anomalies that help us classify with high confidence if an individual is exploiting the game's system. \n",
    "\n",
    "However, a single series is not estabilished with a temporal pattern. The occurence of anomalous events does not directly and completely depend on the timestamp, but is a good feature to track these events. For example, a cheater may only use cheats every alternate round, or in a random pattern, so as to not be too obvious while using exploitative methods. The goal is for the model to identify an individual(s) within a unit that exhibits anomalous behaviour (like getting an extremely high number of kills, instantly spotting or snapping to enemy hitboxes, unusual pitch and yaw changes during movement and kills etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anticheat_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
